{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Scikit_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OW44TIzwLJ1Z",
        "colab_type": "code",
        "outputId": "eba59196-362b-4d0e-8b17-a6f9d2cabb29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpbeqByQL3w0",
        "colab_type": "code",
        "outputId": "7128e5db-050b-4e45-faa7-665d84034ef1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# cd /content/drive/My Drive/'Colab Notebooks'/\n",
        "cd /content/drive/My Drive/Walmart_Competition "
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Walmart_Competition\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZT77kZ1MC6d",
        "colab_type": "code",
        "outputId": "6dda25e4-c344-419f-b98b-504979bfda37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "features.csv                                        sampleSubmission.csv\n",
            "Keras_pickle_model.pkl                              Scikit_model.ipynb\n",
            "Linear_Regression_NN.ipynb                          stores.csv\n",
            "LinearRegression_Regularization_Dropout_Adam.ipynb  test.csv\n",
            "ML_models.ipynb                                     train.csv\n",
            "RF_pickle_model.pkl                                 Walmart_Comp.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuM5BKc5Ml-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqwTS7qPQHss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sklearn Imports\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
        "import xgboost as xgb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHUa57xjQItn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Keras Imports\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhiS3Z7MMD2S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_features = pd.read_csv('features.csv')\n",
        "df_stores = pd.read_csv('stores.csv')\n",
        "df_test = df_test_for_submission = pd.read_csv('test.csv')\n",
        "df_train = pd.read_csv('train.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqUNVE1pMkbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_frame = pd.merge(df_train,df_features,on=['Store','Date','IsHoliday'])\n",
        "data_frame_test = pd.merge(df_test,df_features,on=['Store','Date','IsHoliday'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQUM4Cr2MsSr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_frame = pd.merge(data_frame,df_stores,on='Store')\n",
        "data_frame_test = pd.merge(data_frame_test,df_stores,on='Store')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZhsHfvIMuhZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_frame.fillna(0,inplace=True)\n",
        "data_frame_test.fillna(0,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86aPOyvGMzHv",
        "colab_type": "code",
        "outputId": "f21d2df9-ad34-405a-99f8-b9af5bd26d62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        }
      },
      "source": [
        "print(data_frame.isna().sum())\n",
        "print(\"-----------------------\")\n",
        "print(data_frame_test.isna().sum())"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Store           0\n",
            "Dept            0\n",
            "Date            0\n",
            "Weekly_Sales    0\n",
            "IsHoliday       0\n",
            "Temperature     0\n",
            "Fuel_Price      0\n",
            "MarkDown1       0\n",
            "MarkDown2       0\n",
            "MarkDown3       0\n",
            "MarkDown4       0\n",
            "MarkDown5       0\n",
            "CPI             0\n",
            "Unemployment    0\n",
            "Type            0\n",
            "Size            0\n",
            "dtype: int64\n",
            "-----------------------\n",
            "Store           0\n",
            "Dept            0\n",
            "Date            0\n",
            "IsHoliday       0\n",
            "Temperature     0\n",
            "Fuel_Price      0\n",
            "MarkDown1       0\n",
            "MarkDown2       0\n",
            "MarkDown3       0\n",
            "MarkDown4       0\n",
            "MarkDown5       0\n",
            "CPI             0\n",
            "Unemployment    0\n",
            "Type            0\n",
            "Size            0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tm-P41StM1VD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_frame[\"Weekly_Sales\"] = np.where(data_frame[\"Weekly_Sales\"] < 0,0,data_frame[\"Weekly_Sales\"])\n",
        "data_frame[\"MarkDown2\"] = np.where(data_frame[\"MarkDown2\"] < 0,0,data_frame[\"MarkDown2\"])\n",
        "data_frame[\"MarkDown3\"] = np.where(data_frame[\"MarkDown3\"] < 0,0,data_frame[\"MarkDown3\"])\n",
        "\n",
        "data_frame_test[\"MarkDown2\"] = np.where(data_frame_test[\"MarkDown2\"] < 0,0,data_frame_test[\"MarkDown2\"])\n",
        "data_frame_test[\"MarkDown3\"] = np.where(data_frame_test[\"MarkDown3\"] < 0,0,data_frame_test[\"MarkDown3\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EL2TbQCMM4wm",
        "colab_type": "code",
        "outputId": "7767690c-40ed-4fc4-e3b4-b4826c462075",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(data_frame[\"Type\"].unique())\n",
        "print(data_frame_test[\"Type\"].unique())"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['A' 'B' 'C']\n",
            "['A' 'B' 'C']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsuGpVBgM682",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_frame[\"Date\"] = pd.to_datetime(data_frame[\"Date\"])\n",
        "data_frame[\"Year\"] = data_frame[\"Date\"].dt.year\n",
        "data_frame[\"Month\"] = data_frame[\"Date\"].dt.month\n",
        "data_frame[\"Day\"] = data_frame[\"Date\"].dt.day\n",
        "\n",
        "data_frame_test[\"Date\"] = pd.to_datetime(data_frame_test[\"Date\"])\n",
        "data_frame_test[\"Year\"] = data_frame_test[\"Date\"].dt.year\n",
        "data_frame_test[\"Month\"] = data_frame_test[\"Date\"].dt.month\n",
        "data_frame_test[\"Day\"] = data_frame_test[\"Date\"].dt.day"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlhTCSurM9aL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_frame = data_frame.drop(\"Date\",axis=1)\n",
        "data_frame_test = data_frame_test.drop(\"Date\",axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09OpYeMbNBj6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_frame[\"IsHoliday\"] = data_frame[\"IsHoliday\"].astype(int)  # False = 0, True = 1\n",
        "data_frame_test[\"IsHoliday\"] = data_frame_test[\"IsHoliday\"].astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yH_pXcSzNESi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "data_frame[\"Type\"] = le.fit_transform(data_frame[\"Type\"])\n",
        "data_frame_test[\"Type\"] = le.fit_transform(data_frame_test[\"Type\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VpopMP6NGbw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = data_frame[\"Weekly_Sales\"].values\n",
        "X = data_frame.drop([\"Weekly_Sales\",\"IsHoliday\",\"CPI\",\"Unemployment\",\"MarkDown1\",\"Year\"],axis=1)\n",
        "wmae_feature = data_frame[\"IsHoliday\"].values\n",
        "X_test = data_frame_test.drop([\"IsHoliday\",\"CPI\",\"Unemployment\",\"MarkDown1\",\"Year\"],axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGp3rfcTNL-t",
        "colab_type": "code",
        "outputId": "a4e1ac42-da8b-4b24-99d4-d06e30d5302e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "#y = data_frame[\"Weekly_Sales\"].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "min_max_X = MinMaxScaler()\n",
        "min_max_y = MinMaxScaler()\n",
        "\n",
        "X = min_max_X.fit_transform(X)\n",
        "X_test = min_max_X.transform(X_test)\n",
        "y = y.reshape(-1,1)\n",
        "y = min_max_y.fit_transform(y)\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "X_test = np.array(X_test)\n",
        "\n",
        "\n",
        "print(X.shape,y.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(421570, 12) (421570, 1)\n",
            "(115064, 12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIYJV6GLO7E4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function of all the Models I have experimented on\n",
        "def Linear_Regression_model(X_train, y_train,X_val,y_val):\n",
        "  \n",
        "  LR = LinearRegression()\n",
        "  LR.fit(X_train, y_train)\n",
        "  score_train_acc = LR.score(X_train, y_train)\n",
        "  print(\"**** TRAINING INFORMATION ****\")\n",
        "  print(\"Training Accuracy: \", score_train_acc)\n",
        "  score_val_acc = LR.score(X_val, y_val)\n",
        "  print(\"Validation Accuracy: \", score_val_acc) \n",
        "  #y_train_check = LR.predict(X_train)\n",
        "  print(\"------------------------------\")\n",
        "  print(\"------------------------------\")\n",
        "  print(\"**** Metrics and Scoring ****\")\n",
        "  y_pred_LR = LR.predict(X_val)\n",
        "  print(\"R2 score: \",r2_score(y_val,y_pred_LR))\n",
        "  print(\"MSE value: \",mean_squared_error(y_val,y_pred_LR))\n",
        "  \n",
        "  \n",
        "  pkl_filename = \"LR_pickle_model.pkl\"\n",
        "  \n",
        "  with open(pkl_filename, 'wb') as file:\n",
        "    pickle.dump(LR, file)\n",
        "  return score_train_acc, score_val_acc\n",
        "\n",
        "def Linear_Regression_Ridge_model(X_train, y_train,X_val,y_val):\n",
        "  \n",
        "  LR_R = Ridge()\n",
        "  parameters = {'alpha':[0.1, 0.001, 1]}\n",
        "  LR_R = GridSearchCV(LR_R, param_grid=parameters ,cv=5)\n",
        "  LR_R.fit(X_train, y_train)\n",
        "  score_train_acc = LR_R.score(X_train, y_train)\n",
        "  print(\"**** TRAINING INFORMATION ****\")\n",
        "  print(\"Training Accuracy: \", score_train_acc)\n",
        "  score_val_acc = LR_R.score(X_val, y_val)\n",
        "  print(\"Validation Accuracy: \", score_val_acc) \n",
        "  #y_train_check = LR.predict(X_train)\n",
        "  print(\"------------------------------\")\n",
        "  print(\"------------------------------\")\n",
        "  print(\"**** Metrics and Scoring ****\")\n",
        "  y_pred_LR = LR_R.predict(X_val)\n",
        "  print(\"R2 score: \",r2_score(y_val,y_pred_LR))\n",
        "  print(\"MSE value: \",mean_squared_error(y_val,y_pred_LR))\n",
        "  print(\"Best Params\", LR_R.best_params_)\n",
        "  \n",
        "  \n",
        "  pkl_filename = \"LR_R_pickle_model.pkl\"\n",
        "  \n",
        "  with open(pkl_filename, 'wb') as file:\n",
        "    pickle.dump(LR_R, file)\n",
        "  return score_train_acc, score_val_acc\n",
        "\n",
        "def Linear_Regression_Lasso_model(X_train, y_train,X_val,y_val):\n",
        "  \n",
        "  LR_L = Lasso()\n",
        "  parameters = {'alpha':[0.1, 0.001, 1]}\n",
        "  LR_L = GridSearchCV(LR_L, param_grid=parameters ,cv=5)\n",
        "  LR_L.fit(X_train, y_train)\n",
        "  score_train_acc = LR_L.score(X_train, y_train)\n",
        "  print(\"**** TRAINING INFORMATION ****\")\n",
        "  print(\"Training Accuracy: \", score_train_acc)\n",
        "  score_val_acc = LR_L.score(X_val, y_val)\n",
        "  print(\"Validation Accuracy: \", score_val_acc) \n",
        "  #y_train_check = LR.predict(X_train)\n",
        "  print(\"------------------------------\")\n",
        "  print(\"------------------------------\")\n",
        "  print(\"**** Metrics and Scoring ****\")\n",
        "  y_pred_LR = LR_L.predict(X_val)\n",
        "  print(\"R2 score: \",r2_score(y_val,y_pred_LR))\n",
        "  print(\"MSE value: \",mean_squared_error(y_val,y_pred_LR))\n",
        "  print(\"Best Params\", LR_L.best_params_)\n",
        "  \n",
        "  \n",
        "  pkl_filename = \"LR_L_pickle_model.pkl\"\n",
        "  \n",
        "  with open(pkl_filename, 'wb') as file:\n",
        "    pickle.dump(LR_L, file)\n",
        "  return score_train_acc, score_val_acc\n",
        "\n",
        "def Linear_Regression_ElasticNet_model(X_train, y_train,X_val,y_val):\n",
        "  \n",
        "  LR_E = ElasticNet()\n",
        "  parameters = {'alpha':[0.1, 0.001, 1],'l1_ratio':[0.2,0.3,0.4,0.5]}\n",
        "  LR_E = GridSearchCV(LR_E, param_grid=parameters ,cv=5)\n",
        "  LR_E.fit(X_train, y_train)\n",
        "  score_train_acc = LR_E.score(X_train, y_train)\n",
        "  print(\"**** TRAINING INFORMATION ****\")\n",
        "  print(\"Training Accuracy: \", score_train_acc)\n",
        "  score_val_acc = LR_E.score(X_val, y_val)\n",
        "  print(\"Validation Accuracy: \", score_val_acc) \n",
        "  #y_train_check = LR.predict(X_train)\n",
        "  print(\"------------------------------\")\n",
        "  print(\"------------------------------\")\n",
        "  print(\"**** Metrics and Scoring ****\")\n",
        "  y_pred_LR = LR_E.predict(X_val)\n",
        "  print(\"R2 score: \",r2_score(y_val,y_pred_LR))\n",
        "  print(\"MSE value: \",mean_squared_error(y_val,y_pred_LR))\n",
        "  print(\"Best Params\", LR_E.best_params_)\n",
        "  \n",
        "  pkl_filename = \"LR_E_pickle_model.pkl\"\n",
        "  \n",
        "  with open(pkl_filename, 'wb') as file:\n",
        "    pickle.dump(LR_E, file)\n",
        "  return score_train_acc, score_val_acc\n",
        "\n",
        "def RF_model(X_train, y_train,X_val,y_val):\n",
        "  RF = RandomForestRegressor(n_estimators=50,criterion='mse')\n",
        "  RF.fit(X_train, y_train)\n",
        "  score_train_acc = RF.score(X_train, y_train)\n",
        "  print(\"**** TRAINING INFORMATION ****\")\n",
        "  print(\"Training Accuracy: \", score_train_acc)\n",
        "  score_val_acc = RF.score(X_val, y_val)\n",
        "  print(\"Validation Accuracy: \", score_val_acc) \n",
        "  #y_train_check = LR.predict(X_train)\n",
        "  print(\"------------------------------\")\n",
        "  print(\"------------------------------\")\n",
        "  print(\"**** Metrics and Scoring ****\")\n",
        "  y_pred_RF = RF.predict(X_val)\n",
        "  print(\"Y_pred_RF values\",y_pred_RF.max())\n",
        "  print(\"R2 score: \",r2_score(y_val,y_pred_RF))\n",
        "  print(\"MSE value: \",np.sqrt(mean_squared_error(y_val,y_pred_RF)))\n",
        "  \n",
        "  pkl_filename = \"RF_pickle_model.pkl\"\n",
        "  with open(pkl_filename, 'wb') as file:\n",
        "    pickle.dump(RF, file)\n",
        "  return score_train_acc, score_val_acc,y_pred_RF\n",
        "\n",
        "def GB_model(X_train, y_train,X_val,y_val):\n",
        "  GB = GradientBoostingRegressor(n_estimators=500,criterion='mse')\n",
        "  GB.fit(X_train, y_train)\n",
        "  score_train_acc = GB.score(X_train, y_train)\n",
        "  print(\"**** TRAINING INFORMATION ****\")\n",
        "  print(\"Training Accuracy: \", score_train_acc)\n",
        "  score_val_acc = GB.score(X_val, y_val)\n",
        "  print(\"Validation Accuracy: \", score_val_acc) \n",
        "  #y_train_check = LR.predict(X_train)\n",
        "  print(\"------------------------------\")\n",
        "  print(\"------------------------------\")\n",
        "  print(\"**** Metrics and Scoring ****\")\n",
        "  y_pred_GB = GB.predict(X_val)\n",
        "  print(\"R2 score: \",r2_score(y_val,y_pred_GB))\n",
        "  print(\"MSE value: \",mean_squared_error(y_val,y_pred_GB))\n",
        "  \n",
        "  pkl_filename = \"GB_pickle_model.pkl\"\n",
        "  with open(pkl_filename, 'wb') as file:\n",
        "    pickle.dump(GB, file)\n",
        "  return score_train_acc, score_val_acc\n",
        "\n",
        "def XGBoost_model(X_train, y_train,X_val,y_val):\n",
        "  XGB = xgb.XGBRegressor(booster='gbtree', colsample_bylevel=1,colsample_bynode=1, \n",
        "                          colsample_bytree=0.8, gamma=0.4,max_delta_step=0,\n",
        "                          learning_rate=0.1,min_child_weight=3, missing=None, \n",
        "                          n_estimators=800, n_jobs=1,random_state=0,reg_alpha=1e-05, \n",
        "                          reg_lambda=1, scale_pos_weight=1,subsample=0.8, verbosity=1)\n",
        "  XGB.fit(X_train, y_train)\n",
        "  score_train_acc = XGB.score(X_train, y_train)\n",
        "  print(\"**** TRAINING INFORMATION ****\")\n",
        "  print(\"Training Accuracy: \", score_train_acc)\n",
        "  score_val_acc = XGB.score(X_val, y_val)\n",
        "  print(\"Validation Accuracy: \", score_val_acc) \n",
        "  #y_train_check = LR.predict(X_train)\n",
        "  print(\"------------------------------\")\n",
        "  print(\"------------------------------\")\n",
        "  print(\"**** Metrics and Scoring ****\")\n",
        "  y_pred_xgb = XGB.predict(X_val)\n",
        "  print(\"R2 score: \",r2_score(y_val,y_pred_xgb))\n",
        "  print(\"MSE value: \",mean_squared_error(y_val,y_pred_xgb))\n",
        "  #print(\"Best Params\", svm.best_params_)\n",
        "  \n",
        "  pkl_filename = \"XGB_pickle_model.pkl\"\n",
        "  with open(pkl_filename, 'wb') as file:\n",
        "    pickle.dump(XGB, file)\n",
        "  return score_train_acc, score_val_acc\n",
        "\n",
        "def KNN_model(X_train, y_train,X_val,y_val):\n",
        "  knn = KNeighborsRegressor(n_neighbors=5,weights='uniform',algorithm='auto')\n",
        "  knn.fit(X_train, y_train)\n",
        "  score_train_acc = knn.score(X_train, y_train)\n",
        "  print(\"**** TRAINING INFORMATION ****\")\n",
        "  print(\"Training Accuracy: \", score_train_acc)\n",
        "  score_val_acc = knn.score(X_val, y_val)\n",
        "  print(\"Validation Accuracy: \", score_val_acc) \n",
        "  #y_train_check = LR.predict(X_train)\n",
        "  print(\"------------------------------\")\n",
        "  print(\"------------------------------\")\n",
        "  print(\"**** Metrics and Scoring ****\")\n",
        "  y_pred_knn = knn.predict(X_val)\n",
        "  print(\"R2 score: \",r2_score(y_val,y_pred_knn))\n",
        "  print(\"MSE value: \",mean_squared_error(y_val,y_pred_knn))\n",
        "  \n",
        "  pkl_filename = \"KNN_pickle_model.pkl\"\n",
        "  with open(pkl_filename, 'wb') as file:\n",
        "    pickle.dump(knn, file)\n",
        "  return score_train_acc, score_val_acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFnDUFecUciN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_val_model(models):\n",
        "  print(\"The model user have provided for tarining:\", models)\n",
        "  learning_rate = 0.0001  # Used for Adam Optimizer\n",
        "  iterr = 50 # Number of Epochs\n",
        "  n_folds = 5 # Number of folds for Cross Validation\n",
        "  bsize = 64  # Batch Size\n",
        "  train_acc, val_acc,y_pred_values = [], [], [] # Lists for storing accuracies on each fold\n",
        "\n",
        "  # Cross validation\n",
        "  kfold = KFold(n_splits=n_folds, shuffle=True, random_state=7)\n",
        "  hist = []\n",
        "  val_hist=[]\n",
        "  acc=[]\n",
        "  val_acc=[]\n",
        "  for train, val in kfold.split(X, y):\n",
        "    X_train, X_val = X[train], X[val] # Grabbing X_train, X_val for Models\n",
        "    y_train, y_val = y[train], y[val] # Grabbiing y_train, y_val for Models\n",
        "    \n",
        "    if models == \"LR\":\n",
        "        lr_model = Linear_Regression_model(X_train, y_train,X_val,y_val)\n",
        "        train_acc.append(lr_model[0])\n",
        "        val_acc.append(lr_model[1])\n",
        "        #print(\"TA\",train_acc)\n",
        "        print(\"Training Accuracy is:\", sum(train_acc)/n_folds)\n",
        "        print(\"Validation Accuracy is:\", sum(val_acc)/n_folds)\n",
        "\n",
        "    elif models == \"LR_R\":\n",
        "        lr_model_r = Linear_Regression_Ridge_model(X_train, y_train,X_val,y_val)\n",
        "        train_acc.append(lr_model_r[0])\n",
        "        val_acc.append(lr_model_r[1])\n",
        "        #print(\"TA\",train_acc)\n",
        "        print(\"**** VALIDATION INFORMATION ****\")\n",
        "        print(\"Training Accuracy During KFolds: \", sum(train_acc)/n_folds)\n",
        "        print(\"Validation Accuracy During KFolds: \", sum(val_acc)/n_folds)\n",
        "        \n",
        "    elif models == \"LR_L\":\n",
        "        lr_model_l = Linear_Regression_Lasso_model(X_train, y_train,X_val,y_val)\n",
        "        train_acc.append(lr_model_l[0])\n",
        "        val_acc.append(lr_model_l[1])\n",
        "        #print(\"TA\",train_acc)\n",
        "        print(\"**** VALIDATION INFORMATION ****\")\n",
        "        print(\"Training Accuracy During KFolds: \", sum(train_acc)/n_folds)\n",
        "        print(\"Validation Accuracy During KFolds: \", sum(val_acc)/n_folds)\n",
        "        \n",
        "    elif models == \"LR_E\":\n",
        "        lr_model_e = Linear_Regression_ElasticNet_model(X_train, y_train,X_val,y_val)\n",
        "        train_acc.append(lr_model_e[0])\n",
        "        val_acc.append(lr_model_e[1])\n",
        "        #print(\"TA\",train_acc)\n",
        "        print(\"**** VALIDATION INFORMATION ****\")\n",
        "        print(\"Training Accuracy During KFolds: \", sum(train_acc)/n_folds)\n",
        "        print(\"Validation Accuracy During KFolds: \", sum(val_acc)/n_folds)\n",
        "\n",
        "    elif models == \"RF\":\n",
        "        rf_model = RF_model(X_train, y_train,X_val,y_val)\n",
        "        train_acc.append(rf_model[0])\n",
        "        val_acc.append(rf_model[1])\n",
        "        y_pred_values.append(rf_model[2])\n",
        "        #print(\"TA\",train_acc)\n",
        "        print(\"**** VALIDATION INFORMATION ****\")\n",
        "        print(\"Training Accuracy During KFolds: \", sum(train_acc)/n_folds)\n",
        "        print(\"Validation Accuracy During KFolds: \", sum(val_acc)/n_folds)\n",
        "        print(\"Y_pred Stats\",y_pred_values)\n",
        "\n",
        "    elif models == \"GB\":\n",
        "        gb_model = GB_model(X_train, y_train,X_val,y_val)\n",
        "        train_acc.append(gb_model[0])\n",
        "        val_acc.append(gb_model[1])\n",
        "        print(\"**** VALIDATION INFORMATION ****\")\n",
        "        print(\"Train Accuracy is:\", sum(train_acc)/n_folds)\n",
        "        print(\"Validation Accuracy is:\", sum(val_acc)/n_folds)\n",
        "\n",
        "    elif models == \"XGB\":\n",
        "        xgb_model = XGBoost_model(X_train, y_train,X_val,y_val)\n",
        "        train_acc.append(xgb_model[0])\n",
        "        val_acc.append(xgb_model[1])\n",
        "        print(\"**** VALIDATION INFORMATION ****\")\n",
        "        print(\"Train Accuracy is:\", sum(train_acc)/n_folds)\n",
        "        print(\"Validation Accuracy is:\", sum(val_acc)/n_folds)\n",
        "\n",
        "    elif models == \"KNN\":\n",
        "        knn_model = KNN_model(X_train, y_train,X_val,y_val)\n",
        "        train_acc.append(knn_model[0])\n",
        "        val_acc.append(knn_model[1])\n",
        "        print(\"**** VALIDATION INFORMATION ****\")\n",
        "        print(\"Train Accuracy is:\", sum(train_acc)/n_folds)\n",
        "        print(\"Validation Accuracy is:\", sum(val_acc)/n_folds)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0ZrzwdjPAGV",
        "colab_type": "code",
        "outputId": "1a4abb9a-c2a7-4967-bf37-27fa1f4956c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "  model = \"RF\" # Depends on User, User can select models to experiment from the given list [\"LR\",\"LR_R\",\"LR_L\",\"LR_E\",\"RF\",\"GB\",\"XGB\",\"KNN\"]\n",
        "  _ = train_val_model(models=model)\n",
        "  for el in _: print(el)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model user have provided for tarining: RF\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:107: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "**** TRAINING INFORMATION ****\n",
            "Training Accuracy:  0.9961272325805336\n",
            "Validation Accuracy:  0.9778422228166128\n",
            "------------------------------\n",
            "------------------------------\n",
            "**** Metrics and Scoring ****\n",
            "Y_pred_RF values 0.4912652399505895\n",
            "R2 score:  0.9778422228166128\n",
            "MSE value:  0.004801914523504878\n",
            "**** VALIDATION INFORMATION ****\n",
            "Training Accuracy During KFolds:  0.1992254465161067\n",
            "Validation Accuracy During KFolds:  0.19556844456332256\n",
            "Y_pred Stats [array([0.04440625, 0.0578545 , 0.00609262, ..., 0.04673568, 0.02182668,\n",
            "       0.00937902])]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:107: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "**** TRAINING INFORMATION ****\n",
            "Training Accuracy:  0.996077159730049\n",
            "Validation Accuracy:  0.9741243100456439\n",
            "------------------------------\n",
            "------------------------------\n",
            "**** Metrics and Scoring ****\n",
            "Y_pred_RF values 0.5001350336696313\n",
            "R2 score:  0.9741243100456439\n",
            "MSE value:  0.00525515424534507\n",
            "**** VALIDATION INFORMATION ****\n",
            "Training Accuracy During KFolds:  0.3984408784621165\n",
            "Validation Accuracy During KFolds:  0.3903933065724513\n",
            "Y_pred Stats [array([0.04440625, 0.0578545 , 0.00609262, ..., 0.04673568, 0.02182668,\n",
            "       0.00937902]), array([0.06790796, 0.01382512, 0.00222622, ..., 0.02230885, 0.00887408,\n",
            "       0.00104389])]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:107: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "**** TRAINING INFORMATION ****\n",
            "Training Accuracy:  0.9961439735865503\n",
            "Validation Accuracy:  0.9723820751515047\n",
            "------------------------------\n",
            "------------------------------\n",
            "**** Metrics and Scoring ****\n",
            "Y_pred_RF values 0.6793738392717603\n",
            "R2 score:  0.9723820751515047\n",
            "MSE value:  0.00546380942404356\n",
            "**** VALIDATION INFORMATION ****\n",
            "Training Accuracy During KFolds:  0.5976696731794265\n",
            "Validation Accuracy During KFolds:  0.5848697216027523\n",
            "Y_pred Stats [array([0.04440625, 0.0578545 , 0.00609262, ..., 0.04673568, 0.02182668,\n",
            "       0.00937902]), array([0.06790796, 0.01382512, 0.00222622, ..., 0.02230885, 0.00887408,\n",
            "       0.00104389]), array([0.01637075, 0.05354669, 0.00653148, ..., 0.00237118, 0.07320432,\n",
            "       0.00518166])]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:107: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "**** TRAINING INFORMATION ****\n",
            "Training Accuracy:  0.9964397036325467\n",
            "Validation Accuracy:  0.9691754146165132\n",
            "------------------------------\n",
            "------------------------------\n",
            "**** Metrics and Scoring ****\n",
            "Y_pred_RF values 0.5178071203720825\n",
            "R2 score:  0.9691754146165132\n",
            "MSE value:  0.005816152598520163\n",
            "**** VALIDATION INFORMATION ****\n",
            "Training Accuracy During KFolds:  0.796957613905936\n",
            "Validation Accuracy During KFolds:  0.778704804526055\n",
            "Y_pred Stats [array([0.04440625, 0.0578545 , 0.00609262, ..., 0.04673568, 0.02182668,\n",
            "       0.00937902]), array([0.06790796, 0.01382512, 0.00222622, ..., 0.02230885, 0.00887408,\n",
            "       0.00104389]), array([0.01637075, 0.05354669, 0.00653148, ..., 0.00237118, 0.07320432,\n",
            "       0.00518166]), array([0.0374632 , 0.03192102, 0.0124722 , ..., 0.0186066 , 0.00308298,\n",
            "       0.0740277 ])]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:107: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "**** TRAINING INFORMATION ****\n",
            "Training Accuracy:  0.9960825230632601\n",
            "Validation Accuracy:  0.9757707169274458\n",
            "------------------------------\n",
            "------------------------------\n",
            "**** Metrics and Scoring ****\n",
            "Y_pred_RF values 0.6121282111701853\n",
            "R2 score:  0.9757707169274458\n",
            "MSE value:  0.005120573089659901\n",
            "**** VALIDATION INFORMATION ****\n",
            "Training Accuracy During KFolds:  0.996174118518588\n",
            "Validation Accuracy During KFolds:  0.9738589479115441\n",
            "Y_pred Stats [array([0.04440625, 0.0578545 , 0.00609262, ..., 0.04673568, 0.02182668,\n",
            "       0.00937902]), array([0.06790796, 0.01382512, 0.00222622, ..., 0.02230885, 0.00887408,\n",
            "       0.00104389]), array([0.01637075, 0.05354669, 0.00653148, ..., 0.00237118, 0.07320432,\n",
            "       0.00518166]), array([0.0374632 , 0.03192102, 0.0124722 , ..., 0.0186066 , 0.00308298,\n",
            "       0.0740277 ]), array([0.03659676, 0.05550533, 0.03028692, ..., 0.0147853 , 0.0011176 ,\n",
            "       0.03482685])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIQRoSV9qtBV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading the trained pickled model\n",
        "pkl_filename = \"RF_pickle_model.pkl\"\n",
        "with open(pkl_filename, 'rb') as file:\n",
        "  trained_model = pickle.load(file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBFTmj_9quGk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_predictions = trained_model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7g5WvnjC0jd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_predictions_train = trained_model.predict(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umaMdZZSUMv4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "f6ad1ce3-0c35-4a85-c363-e32d068b1e6c"
      },
      "source": [
        "y_predictions_train"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.03659676, 0.07113874, 0.01887281, ..., 0.07815377, 0.00928875,\n",
              "       0.00111356])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFf9FTjVR6ZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_wmae(y_predictions,y_truth,wmae_feature):\n",
        "  wmae = np.zeros(y_predictions.shape)\n",
        "  y_truth = y_truth.reshape(-1,1)\n",
        "  #print(y_predictions.shape, y_train.shape)\n",
        "  for i in range(len(y_predictions)):\n",
        "    if wmae_feature[i] == 1:\n",
        "      wmae[i] = 5*np.absolute(y[i]-y_predictions[i])\n",
        "    else:\n",
        "      wmae[i] = np.absolute(y[i]-y_predictions[i])\n",
        "      \n",
        "  wmae_feature = np.where(wmae_feature==1,5,wmae_feature)\n",
        "  wmae_feature = np.where(wmae_feature==0,1,wmae_feature)\n",
        "  return np.sum(wmae)/np.sum(wmae_feature)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X634Epz4SCSz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ef4e9803-ed0b-408e-c7be-3286e24ea665"
      },
      "source": [
        "print(calculate_wmae(y_predictions_train,y,wmae_feature))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0011948000090987031\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGQSXpk8JiGg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_actual_pred = min_max_y.inverse_transform(y_predictions.reshape(-1,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkRT92BFbB7Y",
        "colab_type": "code",
        "outputId": "0cce8932-d93f-45d5-a1fd-0e1634bdede5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_actual_pred.max()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "508693.3886"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JS-fYyRX0IT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test_for_submission = df_test_for_submission.drop(\"IsHoliday\",axis=1).values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SH_y0HWGbZOz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ret = np.column_stack((X_test_for_submission, y_actual_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vD6F2W_bhnB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.DataFrame(ret).to_csv(\"Submission.csv\", sep = \",\", header = [\"Store\", \"Department\", \"Datetriplet\", \"Weekley_Sales\"], index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHTGtMxtY9nU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}